---
tags:
  - Multivariable_Calculus
---

局部极值点的偏导数

[[线性代数二次型]]，

#这篇笔记结合线性代数来写

现在我懒得写了



## 最小二乘法

把误差平方和当作一个关于参数的函数，然后对每个参数求偏导，让这些偏导数为 0（或沿负梯度方向下降），就能找到使误差最小的参数。



### 最小二乘函数

给定数据点 $(x_i, y_i)$，模型写成
$$
\hat y_i = f(x_i;\,\theta)
$$
残差（误差）：
$$
r_i(\theta)=\hat y_i - y_i = f(x_i;\theta)-y_i
$$
最小二乘目标函数（误差平方和）：
$$
S(\theta)=\sum_{i=1}^n r_i(\theta)^2
$$
问题变成：**最小化 $S(\theta)$**。



### 正规方程

#### 拟合直线 $\hat y = ax+b$

$$
S(a,b)=\sum_{i=1}^n (ax_i+b-y_i)^2
$$

对参数求偏导：
$$
\frac{\partial S}{\partial a}=2\sum_{i=1}^n (ax_i+b-y_i)\,x_i
$$
令它们等于 0（极值点的必要条件）：
$$
\sum (ax_i+b-y_i)\,x_i = 0
$$
这就是一组关于 $a,b$ 的线性方程，解出来就是最小二乘的最佳拟合直线参数。



### 矩阵形式

一般线性回归写成：
$$
\hat y = X\beta,\quad S(\beta)=\|X\beta-y\|^2
$$
这里 $\beta$ 是参数向量（每个分量对应一个参数），偏导数拼在一起就是梯度：
$$
\nabla_\beta S = 2X^\top (X\beta-y)
$$
令梯度为 0：
$$
X^\top(X\beta-y)=0 \quad \Rightarrow \quad X^\top X\,\beta = X^\top y
$$
这就是**正规方程**。
[[投影、投影矩阵#^325100|线性代数中的正规方程]]
